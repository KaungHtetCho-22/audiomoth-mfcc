{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of audio data representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Waveform \n",
    "- time domain representation of sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array: [-1.4068222e-03 -4.4607258e-04 -4.1098078e-04 ...  7.9623051e-06\n",
      " -3.0417003e-05  1.2765067e-05]\n",
      "array_shape: (117601,)\n",
      "sampling_rate: 22050\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "array, sampling_rate = librosa.load(librosa.ex(\"trumpet\"))\n",
    "\n",
    "print(f'array: {array}')\n",
    "print(f'array_shape: {array.shape}')\n",
    "print(f'sampling_rate: {sampling_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dataset.datatset import TestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array: [-4.8978515e-03 -7.2130230e-03 -9.6160118e-05 ...  3.8444130e-03\n",
      "  5.0813844e-03  2.5231761e-03]\n",
      "array_shape: (19200000,)\n",
      "duration: 600.0\n",
      "seconds: [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320, 325, 330, 335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385, 390, 395, 400, 405, 410, 415, 420, 425, 430, 435, 440, 445, 450, 455, 460, 465, 470, 475, 480, 485, 490, 495, 500, 505, 510, 515, 520, 525, 530, 535, 540, 545, 550, 555, 560, 565, 570, 575, 580, 585, 590, 595]\n",
      "filename: 00-07-52_dur=600secs\n",
      "row_ids: ['00-07-52_dur=600secs_5', '00-07-52_dur=600secs_10', '00-07-52_dur=600secs_15', '00-07-52_dur=600secs_20', '00-07-52_dur=600secs_25', '00-07-52_dur=600secs_30', '00-07-52_dur=600secs_35', '00-07-52_dur=600secs_40', '00-07-52_dur=600secs_45', '00-07-52_dur=600secs_50', '00-07-52_dur=600secs_55', '00-07-52_dur=600secs_60', '00-07-52_dur=600secs_65', '00-07-52_dur=600secs_70', '00-07-52_dur=600secs_75', '00-07-52_dur=600secs_80', '00-07-52_dur=600secs_85', '00-07-52_dur=600secs_90', '00-07-52_dur=600secs_95', '00-07-52_dur=600secs_100', '00-07-52_dur=600secs_105', '00-07-52_dur=600secs_110', '00-07-52_dur=600secs_115', '00-07-52_dur=600secs_120', '00-07-52_dur=600secs_125', '00-07-52_dur=600secs_130', '00-07-52_dur=600secs_135', '00-07-52_dur=600secs_140', '00-07-52_dur=600secs_145', '00-07-52_dur=600secs_150', '00-07-52_dur=600secs_155', '00-07-52_dur=600secs_160', '00-07-52_dur=600secs_165', '00-07-52_dur=600secs_170', '00-07-52_dur=600secs_175', '00-07-52_dur=600secs_180', '00-07-52_dur=600secs_185', '00-07-52_dur=600secs_190', '00-07-52_dur=600secs_195', '00-07-52_dur=600secs_200', '00-07-52_dur=600secs_205', '00-07-52_dur=600secs_210', '00-07-52_dur=600secs_215', '00-07-52_dur=600secs_220', '00-07-52_dur=600secs_225', '00-07-52_dur=600secs_230', '00-07-52_dur=600secs_235', '00-07-52_dur=600secs_240', '00-07-52_dur=600secs_245', '00-07-52_dur=600secs_250', '00-07-52_dur=600secs_255', '00-07-52_dur=600secs_260', '00-07-52_dur=600secs_265', '00-07-52_dur=600secs_270', '00-07-52_dur=600secs_275', '00-07-52_dur=600secs_280', '00-07-52_dur=600secs_285', '00-07-52_dur=600secs_290', '00-07-52_dur=600secs_295', '00-07-52_dur=600secs_300', '00-07-52_dur=600secs_305', '00-07-52_dur=600secs_310', '00-07-52_dur=600secs_315', '00-07-52_dur=600secs_320', '00-07-52_dur=600secs_325', '00-07-52_dur=600secs_330', '00-07-52_dur=600secs_335', '00-07-52_dur=600secs_340', '00-07-52_dur=600secs_345', '00-07-52_dur=600secs_350', '00-07-52_dur=600secs_355', '00-07-52_dur=600secs_360', '00-07-52_dur=600secs_365', '00-07-52_dur=600secs_370', '00-07-52_dur=600secs_375', '00-07-52_dur=600secs_380', '00-07-52_dur=600secs_385', '00-07-52_dur=600secs_390', '00-07-52_dur=600secs_395', '00-07-52_dur=600secs_400', '00-07-52_dur=600secs_405', '00-07-52_dur=600secs_410', '00-07-52_dur=600secs_415', '00-07-52_dur=600secs_420', '00-07-52_dur=600secs_425', '00-07-52_dur=600secs_430', '00-07-52_dur=600secs_435', '00-07-52_dur=600secs_440', '00-07-52_dur=600secs_445', '00-07-52_dur=600secs_450', '00-07-52_dur=600secs_455', '00-07-52_dur=600secs_460', '00-07-52_dur=600secs_465', '00-07-52_dur=600secs_470', '00-07-52_dur=600secs_475', '00-07-52_dur=600secs_480', '00-07-52_dur=600secs_485', '00-07-52_dur=600secs_490', '00-07-52_dur=600secs_495', '00-07-52_dur=600secs_500', '00-07-52_dur=600secs_505', '00-07-52_dur=600secs_510', '00-07-52_dur=600secs_515', '00-07-52_dur=600secs_520', '00-07-52_dur=600secs_525', '00-07-52_dur=600secs_530', '00-07-52_dur=600secs_535', '00-07-52_dur=600secs_540', '00-07-52_dur=600secs_545', '00-07-52_dur=600secs_550', '00-07-52_dur=600secs_555', '00-07-52_dur=600secs_560', '00-07-52_dur=600secs_565', '00-07-52_dur=600secs_570', '00-07-52_dur=600secs_575', '00-07-52_dur=600secs_580', '00-07-52_dur=600secs_585', '00-07-52_dur=600secs_590', '00-07-52_dur=600secs_595']\n",
      "********************************************************************************************************************************************************************************************************\n",
      "test_df:                     row_id  seconds\n",
      "0   00-07-52_dur=600secs_5        5\n",
      "1  00-07-52_dur=600secs_10       10\n",
      "2  00-07-52_dur=600secs_15       15\n",
      "3  00-07-52_dur=600secs_20       20\n",
      "4  00-07-52_dur=600secs_25       25\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sample_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_df: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_df\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TestDataset(\n\u001b[1;32m     26\u001b[0m         df\u001b[38;5;241m=\u001b[39mtest_df, \n\u001b[1;32m     27\u001b[0m         clip\u001b[38;5;241m=\u001b[39mclip\n\u001b[1;32m     28\u001b[0m     )\n",
      "File \u001b[0;32m~/kaung/audiomoth-mfcc/dataset/datatset.py:16\u001b[0m, in \u001b[0;36mTestDataset.__init__\u001b[0;34m(self, df, clip, cfg)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip \u001b[38;5;241m=\u001b[39m clip\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msr \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39msample_rate\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m cfg\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sample_rate'"
     ]
    }
   ],
   "source": [
    "clip, _ = librosa.load('00-07-52_dur=600secs.wav', sr=32000)\n",
    "\n",
    "print(f'array: {clip}')\n",
    "print(f'array_shape: {clip.shape}')\n",
    "\n",
    "duration = librosa.get_duration(y=clip, sr=32000)\n",
    "print(f'duration: {duration}')\n",
    "\n",
    "seconds = list(range(5, int(duration), 5))  # Ensure it covers the whole audio length\n",
    "print(f'seconds: {seconds}')\n",
    "\n",
    "filename = Path('00-07-52_dur=600secs.wav').stem\n",
    "print(f'filename: {filename}')\n",
    "\n",
    "row_ids = [filename + f\"_{second}\" for second in seconds] # Generate row ids for each segment\n",
    "print(f'row_ids: {row_ids}')\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "        \"row_id\": row_ids,\n",
    "        \"seconds\": seconds,\n",
    "    })\n",
    "print('*' * 200)\n",
    "print(f'test_df: {test_df.head()}')\n",
    "\n",
    "dataset = TestDataset(\n",
    "        df=test_df, \n",
    "        clip=clip\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "plt.figure().set_figwidth(12)\n",
    "librosa.display.waveshow(array, sr=sampling_rate)\n",
    "\n",
    "clip, _ = librosa.load(audio_path, sr=32000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Frequency spectrum \n",
    "- frequency domain representation\n",
    "- The spectrum is computed using the discrete Fourier transform or DFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dft_input = array[:4096]\n",
    "\n",
    "# calculate the DFT\n",
    "window = np.hanning(len(dft_input))\n",
    "windowed_input = dft_input * window\n",
    "dft = np.fft.rfft(windowed_input)\n",
    "\n",
    "# get the amplitude spectrum in decibels\n",
    "amplitude = np.abs(dft)\n",
    "amplitude_db = librosa.amplitude_to_db(amplitude, ref=np.max)\n",
    "\n",
    "# get the frequency bins\n",
    "frequency = librosa.fft_frequencies(sr=sampling_rate, n_fft=len(dft_input))\n",
    "\n",
    "plt.figure().set_figwidth(12)\n",
    "plt.plot(frequency, amplitude_db)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Amplitude (dB)\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D = librosa.stft(array)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "plt.figure().set_figwidth(12)\n",
    "librosa.display.specshow(S_db, x_axis=\"time\", y_axis=\"hz\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mel-spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(y=array, sr=sampling_rate, n_mels=128, fmax=8000)\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure().set_figwidth(12)\n",
    "librosa.display.specshow(S_dB, x_axis=\"time\", y_axis=\"mel\", sr=sampling_rate, fmax=8000)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By nature, a sound wave is a continuous signal, meaning it contains an infinite number of signal values in a given time.\n",
    "(.wav/ .mp3/ .flac) These formats mainly differ in how they compress the digital representation of the audio signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analog signal is first captured by a microphone, which converts the sound waves into an electrical signal. The electrical signal is then digitized by an Analog-to-Digital Converter to get the digital representation through sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling rate (also called sampling frequency) is the number of samples taken in one second and is measured in hertz (Hz). To give you a point of reference, CD-quality audio has a sampling rate of 44,100 Hz, meaning samples are taken 44,100 times per second. For comparison, high-resolution audio has a sampling rate of 192,000 Hz or 192 kHz. A common sampling rate used in training speech models is 16,000 Hz or 16 kHz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s important to ensure that all audio examples in your dataset have the same sampling rate when working on any audio task. If you plan to use custom audio data to fine-tune a pre-trained model, the sampling rate of your data should match the sampling rate of the data the model was pre-trained on. The sampling rate determines the time interval between successive audio samples, which impacts the temporal resolution of the audio data. Consider an example: a 5-second sound at a sampling rate of 16,000 Hz will be represented as a series of 80,000 values, while the same 5-second sound at a sampling rate of 8,000 Hz will be represented as a series of 40,000 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with continuous audio signals, the amplitude of digital audio is typically expressed in decibels (dB). Since human hearing is logarithmic in nature — our ears are more sensitive to small fluctuations in quiet sounds than in loud sounds — the loudness of a sound is easier to interpret if the amplitudes are in decibels, which are also logarithmic. The decibel scale for real-world audio starts at 0 dB, which represents the quietest possible sound humans can hear, and louder sounds have larger values. However, for digital audio signals, 0 dB is the loudest possible amplitude, while all other amplitudes are negative. As a quick rule of thumb: every -6 dB is a halving of the amplitude, and anything below -60 dB is generally inaudible unless you really crank up the volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
